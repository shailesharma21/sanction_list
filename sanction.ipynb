{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8389bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shailesh.sharma\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import jellyfish as jf \n",
    "from cleanco import basename\n",
    "import requests\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce6c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scrap(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    sl = requests.get(url, stream=True)\n",
    "    f = open(filename,'wb')\n",
    "    for chunk in sl.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    return\n",
    "\n",
    "data_scrap('https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1059386/UK_Sanctions_List.ods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f7072ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supplier_data_load():\n",
    "    #df1 = pd.read_csv('supplier_list.csv')\n",
    "    #supplier_list = df1.loc[df1['Name'].str.startswith('RU')]\n",
    "    translated_names = pd.read_csv('translated_for_streamlit.csv')\n",
    "    return translated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80c27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supplier_data_load_all_countries():\n",
    "    df1 = pd.read_csv('supplier_list.csv')\n",
    "    df1 = df1.loc[~df1['Name'].str.startswith('RU')]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f5d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uk_sanction_data_load():\n",
    "    df2 = pd.read_excel('UK_Sanctions_List.ods', engine='odf',skiprows=1,header=1)\n",
    "    uk_sanctions = df2.loc[df2['Unique ID'].str.startswith('RUS')]\n",
    "    uk_sanction = uk_sanctions.loc[uk_sanctions['Individual, Entity, Ship']=='Entity']\n",
    "    return uk_sanction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57547324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_modified_str(input_str):\n",
    "    # Transform to lower case\n",
    "    input_str = input_str.strip().lower()\n",
    "    # Replace '&' char to word 'and'\n",
    "    input_str = input_str.replace(' & ', ' and ')\n",
    "    # Remove all other special chars\n",
    "    input_str = \" \".join(re.findall(\"[a-zA-Z0-9]+\", input_str))\n",
    "    # Remove extra spaces\n",
    "    input_str = \" \".join(input_str.split())\n",
    "    return input_str.strip()\n",
    "\n",
    "# Function to decode any string type to unicode\n",
    "def to_unicode(obj, encoding='utf-8'):\n",
    "    if not isinstance(obj, str):\n",
    "        return obj.decode(encoding, errors='ignore')\n",
    "    return obj\n",
    "\n",
    "\n",
    "def name_match(name1, name2):\n",
    "    name1 = name1.split()\n",
    "    name2 = name2.split()\n",
    "    if name1 and name2:\n",
    "        ratio1 = 0.0\n",
    "        for i in range(len(name1)):\n",
    "            for j in range(i, len(name2)):\n",
    "                if fuzz.ratio(name1[i], name2[j]) > 90:\n",
    "                    ratio1 += 1.0\n",
    "                    break\n",
    "        try:\n",
    "            ratio1 = 100 * (ratio1 / len(name1))\n",
    "        except ZeroDivisionError:\n",
    "            ratio1 = 0.0\n",
    "        ratio2 = 0.0\n",
    "        for i in range(len(name2)):\n",
    "            for j in range(i, len(name1)):\n",
    "                if fuzz.ratio(name2[i], name1[j]) > 90:\n",
    "                    ratio2 += 1.0\n",
    "                    break\n",
    "        try:\n",
    "            ratio2 = 100 * (ratio2 / len(name2))\n",
    "        except ZeroDivisionError:\n",
    "            ratio2 = 0.0\n",
    "        return int(max(ratio1, ratio2))\n",
    "    return 0\n",
    "\n",
    "# Function to calculate fuzzy match score for two given strings\n",
    "def f_name_match_score(str1, str2):\n",
    "    # Transform name\n",
    "    if len(str1) > 1 and len(str2) > 1:\n",
    "        str1 = f_get_modified_str(str1)\n",
    "        str2 = f_get_modified_str(str2)\n",
    "        # Convert to unicode to avoid error\n",
    "        str1 = to_unicode(str1)\n",
    "        str2 = to_unicode(str2)\n",
    "        # Compute match scores\n",
    "        score1 = fuzz.ratio(str1, str2)\n",
    "        score2 = fuzz.token_sort_ratio(str1, str2)\n",
    "        score3 = jf.levenshtein_distance(str1,str2)\n",
    "        score3 = (1-(score3/max(len(str1),len(str2))))*100\n",
    "        #score4 = name_match(str1, str2)\n",
    "        if len(str1.split()) == 1:\n",
    "            score4 = fuzz.ratio(str1.split()[0], str2.split()[0])\n",
    "        s_max = max(score1, score2, score3)\n",
    "    else:\n",
    "        s_max = 0\n",
    "    return s_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc42460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_legal_entities(entity_name):\n",
    "    rp = ['LLC','PJSC','CJSC','IP','GUP','OJSC','JSC','OOO','OO','Limited Liability Company','Open Joint Stock Company','Joint-Stock Company','Public Joint Stock Company','Joint Stock Company','Joint-stock company','AO']\n",
    "    for k in rp:\n",
    "        if k in entity_name:\n",
    "            entity_name = entity_name.replace(k,'')\n",
    "    # Using basename twice for better clean\n",
    "    entity_name = basename(entity_name)\n",
    "    entity_name = basename(entity_name)\n",
    "    # Remove all other special chars\n",
    "    entity_name = \" \".join(re.findall(\"[a-zA-Z0-9]+\", entity_name))\n",
    "    # Remove extra spaces\n",
    "    entity_name = \" \".join(entity_name.split())\n",
    "    return entity_name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9e3bab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity matching for Russia only\n",
    "def entity_matching_for_rus(translated_list, uk_sanction_list):    \n",
    "    df = pd.DataFrame(columns=['Match1','Score1','Match2','Score2','Match3','Score3','Match4','Score4','Match5','Score5'])\n",
    "    df.index.name = 'Supplier Name'\n",
    "    fl_dict = {}\n",
    "    for i in translated_list['Translated value using Google Translate']:\n",
    "        t_dict={}\n",
    "        sorted_dict = {}\n",
    "        i = clean_company_legal_entities(i)\n",
    "        for j in uk_sanction_list['Name 6']:\n",
    "            j = clean_company_legal_entities(j)\n",
    "            if j not in t_dict.keys():\n",
    "                t_dict[j] = f_name_match_score(i,j)\n",
    "        sorted_dict = sorted(t_dict.items(),key = lambda kv: kv[1],reverse=True)\n",
    "        lst = sorted_dict[:5]\n",
    "        df = df.append(pd.Series({'Match1':lst[0][0],'Score1':lst[0][1],'Match2':lst[1][0],'Score2':lst[1][1],'Match3':lst[2][0],'Score3':lst[2][1],'Match4':lst[3][0],'Score4':lst[3][1],'Match5':lst[4][0],'Score5':lst[4][1]},name=i))\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    df.to_csv('top_Match_rus2.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a306677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_names = supplier_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959d77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_sanction = uk_sanction_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3680ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_matching_for_rus(translated_names, uk_sanction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3b4a9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching for rest of the countries\n",
    "df1 = df1.loc[~df1['Name'].str.startswith('RU')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f8e23817",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Entity matching for Rest countries including Macao\n",
    "def entity_matching_for_all(supplier_list, uk_sanction_list):    \n",
    "    df = pd.DataFrame(columns=['Country Code','Match1','Score1','Match2','Score2','Match3','Score3','Match4','Score4','Match5','Score5'])\n",
    "    df.index.name = 'Supplier Name'\n",
    "    fl_dict = {}\n",
    "    for i,cc in zip(supplier_list['Display Name'],supplier_list['Name']):\n",
    "        t_dict={}\n",
    "        sorted_dict = {}\n",
    "        i = str(i)\n",
    "        i = clean_company_legal_entities(i)\n",
    "        for j in uk_sanction_list['Name 6']:\n",
    "            j = clean_company_legal_entities(j)\n",
    "            if j not in t_dict.keys():\n",
    "                t_dict[j] = f_name_match_score(i,j)\n",
    "        sorted_dict = sorted(t_dict.items(),key = lambda kv: kv[1],reverse=True)\n",
    "        lst = sorted_dict[:5]\n",
    "        df = df.append(pd.Series({'Country Code':cc ,'Match1':lst[0][0],'Score1':lst[0][1],'Match2':lst[1][0],'Score2':lst[1][1],'Match3':lst[2][0],'Score3':lst[2][1],'Match4':lst[3][0],'Score4':lst[3][1],'Match5':lst[4][0],'Score5':lst[4][1]},name=i))\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    df.to_csv('top_match_for_all_countries2.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8a3d1ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_matching_for_all(df1,uk_sanction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961c079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3da04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StreamLit supplier file upload function\n",
    "def entity_matching_for_streamlit(supplier_list,uk_sanction_list):\n",
    "    supplier_list = supplier_list['Display Name'].tolist()\n",
    "    supplier_list = [clean_company_legal_entities(x) for x in supplier_list]\n",
    "    uk_sanction = uk_sanction_list['Name 6'].tolist()\n",
    "    uk_sanction = [clean_company_legal_entities(x) for x in uk_sanction]\n",
    "    cross_prod = list(itertools.product(supplier_list,uk_sanction)) \n",
    "    t_dict={}\n",
    "    for i in cross_prod:\n",
    "        t_dict[i] = f_name_match_score(i[0],i[1])\n",
    "    lst = list(t_dict.items())\n",
    "    df1 = pd.DataFrame(lst,columns=['Supp Name','Score'])\n",
    "    df1[['Supplier Name','Sanctioned Name']] = pd.DataFrame(df1['Supp Name'].tolist(),index=df1.index)\n",
    "    df1['Match Found'] = np.where(df1['Score']>95,'Yes','No')\n",
    "    df1['Sanctioned Org Name'] = np.where(df1['Score']>95,df1['Sanctioned Name'],'')\n",
    "    df1.drop(df1.columns[[0,1,3]],axis=1,inplace=True)\n",
    "    df1.drop_duplicates(keep='first',inplace=True)\n",
    "    df1 = df1.set_index('Supplier Name')\n",
    "    df1.to_csv('streamlit_matching_file.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c7393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplier_list = supplier_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec301d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_matching_for_streamlit(supplier_list,uk_sanction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5445dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
